# Scraper Framer Marketplace V2

Zaawansowany scraper do zbierania danych z Framer Marketplace, umoÅ¼liwiajÄ…cy automatyzacjÄ™ pobierania informacji o:

- **Produktach**: Szablony (templates), Komponenty (components), Wektory (vectors), **Wtyczki (plugins)** â­
- **TwÃ³rcach/UÅ¼ytkownikach**: Profile z username (moÅ¼e zawieraÄ‡ znaki specjalne)
- **Kategoriach**: Kategorie produktÃ³w w marketplace
- **Recenzjach**: Opinie i oceny produktÃ³w

## ğŸ“š Dokumentacja

### GÅ‚Ã³wne Dokumenty

1. **[STACK_TECHNICZNY.md](./STACK_TECHNICZNY.md)** - SzczegÃ³Å‚owy opis stacku technicznego, w tym:
   - Biblioteki Python i narzÄ™dzia
   - Opcje baz danych
   - GitHub Actions i Vercel
   - Rekomendacje deployment

2. **[PROPOZYCJA_ARCHITEKTURY.md](./PROPOZYCJA_ARCHITEKTURY.md)** - Propozycja struktury projektu:
   - Struktura folderÃ³w
   - Opis komponentÃ³w
   - Flow scrapowania
   - Deployment strategy

3. **[Cursor Rules/REKOMENDACJE_SCRAPERA_FRAMER.md](./Cursor%20Rules/REKOMENDACJE_SCRAPERA_FRAMER.md)** - SzczegÃ³Å‚owa analiza Framer Marketplace:
   - Analiza techniczna strony
   - Struktura URL-i i selektory CSS
   - Zalecane dane do zbierania
   - Uwagi techniczne

## ğŸš€ Quick Start

### 1. PrzeglÄ…d Dokumentacji

Najpierw przeczytaj dokumenty, aby zrozumieÄ‡:
- Jak dziaÅ‚a Framer Marketplace (REKOMENDACJE_SCRAPERA_FRAMER.md)
- Jaki stack techniczny jest rekomendowany (STACK_TECHNICZNY.md)
- Jak zorganizowaÄ‡ projekt (PROPOZYCJA_ARCHITEKTURY.md)

### 2. Setup Projektu

```bash
# StwÃ³rz strukturÄ™ projektu zgodnie z PROPOZYCJA_ARCHITEKTURY.md
# Zainstaluj zaleÅ¼noÅ›ci
pip install -r requirements.txt

# Skonfiguruj zmienne Å›rodowiskowe
cp .env.example .env
# Edytuj .env z odpowiednimi wartoÅ›ciami
```

### 3. Uruchomienie

```bash
# Podstawowe uruchomienie (scrapuje wszystkie produkty)
python -m src.main

# Ograniczenie liczby produktÃ³w (np. 10 dla testÃ³w)
python -m src.main 10

# Export danych do CSV
python scripts/export_data.py

# Lub przez GitHub Actions (scheduled lub manual)
# Zobacz .github/workflows/scrape.yml
```

## ğŸ› ï¸ Stack Techniczny (Podsumowanie)

### Backend
- **Python 3.11+** - jÄ™zyk gÅ‚Ã³wny
- **httpx** - async HTTP client
- **BeautifulSoup4** - parsowanie HTML
- **pydantic** - walidacja danych
- **SQLAlchemy** - ORM (opcjonalnie)

### Deployment & Automation
- **GitHub Actions** - automatyczne scrapowanie (scheduled)
- **Vercel** - API i dashboard (opcjonalnie)
- **PostgreSQL/Supabase** - baza danych (opcjonalnie)

### Storage
- **JSON/CSV** - podstawowe (zalecane na start)
- **PostgreSQL** - dla wiÄ™kszych projektÃ³w
- **GitHub Artifacts** - backup danych

## ğŸ“‹ FunkcjonalnoÅ›ci

### âœ… Zaimplementowane

- [x] Scrapowanie produktÃ³w z sitemap.xml (templates/components/vectors/**plugins**)
- [x] Scrapowanie danych twÃ³rcÃ³w (profile z `@username`)
- [x] Scrapowanie kategorii (opcjonalnie)
- [x] Parsowanie recenzji produktÃ³w
- [x] Rate limiting i error handling
- [x] Zapis do JSON/CSV (organizacja wedÅ‚ug typu produktu)
- [x] Automatyzacja przez GitHub Actions (scheduled + manual)
- [x] Resume capability (wznowienie po przerwie) - checkpoint system
- [x] Walidacja danych (Pydantic v2)
- [x] Monitoring i logowanie (structlog)
- [x] Normalizacja danych (Opcja B - raw + normalized)
- [x] ObsÅ‚uga rÃ³Å¼nych typÃ³w produktÃ³w (rÃ³Å¼ne statystyki i pola)
- [x] CI/CD workflow (tests, linting, formatting)
- [x] Metrics tracking (success rate, errors, timing)

### ğŸ”® Opcjonalne (Faza 2+)

- [ ] API endpoints (FastAPI)
- [ ] Dashboard (Next.js)
- [ ] Baza danych (PostgreSQL)
- [ ] Error tracking (Sentry)
- [ ] Notyfikacje (Slack/Email)

## ğŸ“ Struktura Projektu

```
scraper-v2/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scrapers/          # Scrapery (sitemap, product, creator, category)
â”‚   â”œâ”€â”€ parsers/           # Parsery HTML (product, creator, review, category)
â”‚   â”œâ”€â”€ models/            # Modele Pydantic (Product, Creator, Review, Category)
â”‚   â”œâ”€â”€ storage/           # Zapis danych (file_storage)
â”‚   â”œâ”€â”€ utils/             # NarzÄ™dzia (logger, rate_limiter, retry, normalizers, checkpoint, metrics)
â”‚   â”œâ”€â”€ config/            # Konfiguracja (settings)
â”‚   â””â”€â”€ main.py            # Entry point
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ products/          # Zapisane produkty (templates/, components/, vectors/, plugins/)
â”‚   â”œâ”€â”€ creators/          # Dane twÃ³rcÃ³w
â”‚   â”œâ”€â”€ categories/        # Dane kategorii
â”‚   â”œâ”€â”€ exports/           # Eksporty CSV
â”‚   â””â”€â”€ checkpoint.json    # Checkpoint dla resume capability
â”œâ”€â”€ tests/                 # Testy jednostkowe
â”œâ”€â”€ scripts/               # Skrypty pomocnicze
â”‚   â”œâ”€â”€ export_data.py     # Export do CSV
â”‚   â””â”€â”€ setup_db.py        # Setup bazy danych
â”œâ”€â”€ .github/workflows/     # GitHub Actions
â”‚   â”œâ”€â”€ scrape.yml         # Scheduled scraping + manual
â”‚   â””â”€â”€ ci.yml             # CI/CD (tests, linting, formatting)
â””â”€â”€ logs/                  # Logi scrapera
```

SzczegÃ³Å‚owa struktura: [PROPOZYCJA_ARCHITEKTURY.md](./PROPOZYCJA_ARCHITEKTURY.md)

## ğŸ” Uwagi Prawne

âš ï¸ **WaÅ¼ne:**
- Przeczytaj Terms of Service Framer przed scrapowaniem
- Respektuj robots.txt
- Nie przeciÄ…Å¼aj serwerÃ³w (rate limiting)
- Nie scrapuj danych osobowych bez zgody
- RozwaÅ¼ kontakt z Framer - mogÄ… oferowaÄ‡ API

## ğŸ“ NastÄ™pne Kroki

1. **Przeczytaj dokumentacjÄ™** - szczegÃ³lnie REKOMENDACJE_SCRAPERA_FRAMER.md
2. **Zdecyduj o stacku** - zobacz STACK_TECHNICZNY.md
3. **StwÃ³rz strukturÄ™ projektu** - zgodnie z PROPOZYCJA_ARCHITEKTURY.md
4. **Zaimplementuj MVP** - podstawowy scraper z sitemap (wszystkie typy produktÃ³w)
5. **Testuj na maÅ‚ej prÃ³bce** - 10-20 produktÃ³w (rÃ³Å¼ne typy)
6. **Setup GitHub Actions** - automatyzacja
7. **Rozszerz funkcjonalnoÅ›ci** - twÃ³rcy, kategorie, recenzje, baza danych

## ğŸ¤ Contributing

Projekt jest w fazie rozwoju. Wszelkie sugestie i PR-y sÄ… mile widziane!

## ğŸ“„ License

[TODO: Dodaj licencjÄ™]

---

*Ostatnia aktualizacja: 2025-11-03*

