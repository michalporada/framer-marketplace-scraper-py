name: Sync JSON to Database

on:
  workflow_dispatch:  # Rƒôczne uruchomienie
  workflow_run:
    workflows: ["Daily Scrape"]
    types:
      - completed
    branches:
      - main
  schedule:
    # Fallback: je≈õli workflow_run nie zadzia≈Ça, uruchom o 8:00 UTC (6h po scrapowaniu o 2:00)
    - cron: '0 8 * * *'

jobs:
  sync:
    runs-on: ubuntu-latest
    # Tylko uruchom je≈õli scrape workflow zako≈Ñczy≈Ç siƒô sukcesem (dla workflow_run trigger)
    if: github.event.workflow_run.conclusion == 'success' || github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Find latest scrape workflow run
        id: find-scrape-run
        continue-on-error: true
        run: |
          # If triggered by workflow_run, use that run_id
          if [ "${{ github.event_name }}" == "workflow_run" ]; then
            RUN_ID="${{ github.event.workflow_run.id }}"
            echo "‚úÖ Using workflow_run trigger: $RUN_ID"
            echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
            echo "found=true" >> $GITHUB_OUTPUT
          else
            # For schedule/workflow_dispatch, find latest successful run
            echo "üîç Looking for latest successful 'Daily Scrape' workflow run..."
            RUN_ID=$(gh run list --workflow=scrape.yml --status=success --limit=1 --json databaseId --jq '.[0].databaseId' 2>/dev/null || echo "")
            
            if [ -z "$RUN_ID" ] || [ "$RUN_ID" == "null" ]; then
              echo "‚ö†Ô∏è No successful scrape workflow run found"
              echo "run_id=" >> $GITHUB_OUTPUT
              echo "found=false" >> $GITHUB_OUTPUT
            else
              echo "‚úÖ Found scrape workflow run: $RUN_ID"
              echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
              echo "found=true" >> $GITHUB_OUTPUT
            fi
          fi
        env:
          GH_TOKEN: ${{ github.token }}
      
      - name: Download artifacts (if available)
        id: download-artifacts
        continue-on-error: true
        if: steps.find-scrape-run.outputs.found == 'true'
        uses: actions/download-artifact@v4
        with:
          name: scraped-data-latest
          path: data/
          github-token: ${{ github.token }}
          repository: ${{ github.repository }}
          run-id: ${{ steps.find-scrape-run.outputs.run_id }}
      
      - name: Check download result
        id: check-download
        run: |
          if [ "${{ steps.download-artifacts.outcome }}" == "success" ]; then
            echo "üîç Checking artifact structure..."
            echo "Contents of data/ directory:"
            ls -la data/ 2>/dev/null || echo "data/ not found"
            echo ""
            echo "Looking for products directory..."
            if [ -d "data/products" ]; then
              echo "‚úÖ Found data/products/"
              ls -la data/products/ | head -10
            elif [ -d "data/data/products" ]; then
              echo "‚úÖ Found data/data/products/ (nested structure)"
              # Move nested structure to expected location
              mv data/data/* data/ 2>/dev/null || true
              rm -rf data/data 2>/dev/null || true
            else
              echo "‚ö†Ô∏è Neither data/products nor data/data/products found"
              echo "Searching for JSON files..."
              find data/ -name "*.json" -type f 2>/dev/null | head -10 || echo "No JSON files found"
            fi
            
            # Check if products directory exists now
            if [ -d "data/products" ] && [ -n "$(ls -A data/products/*/*.json 2>/dev/null)" ]; then
              echo "‚úÖ Artifact downloaded and extracted successfully"
              echo "downloaded=true" >> $GITHUB_OUTPUT
            else
              echo "‚ö†Ô∏è Artifact downloaded but no product files found"
              echo "downloaded=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "downloaded=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Check if artifact was downloaded
        run: |
          if [ "${{ steps.check-download.outputs.downloaded }}" != "true" ]; then
            echo "‚ö†Ô∏è Artifact 'scraped-data-latest' not found or download failed"
            echo "This may happen if:"
            echo "  - Scrape workflow hasn't run yet"
            echo "  - Scrape workflow failed"
            echo "  - Artifact expired (retention: 7 days)"
            echo ""
            echo "Checking if data/ directory exists locally..."
            if [ -d "data/products" ] && [ -n "$(ls -A data/products/*/*.json 2>/dev/null)" ]; then
              echo "‚úÖ Found local data files - will use them instead"
            else
              echo "‚ùå No data found. Cannot proceed with sync."
              exit 1
            fi
          else
            echo "‚úÖ Artifact downloaded successfully"
          fi
      
      - name: Check if data exists
        run: |
          if [ ! -d "data/products" ]; then
            echo "‚ùå data/products directory not found"
            echo "Available directories:"
            ls -la data/ 2>/dev/null || echo "data/ directory not found"
            exit 1
          fi
          
          json_count=$(find data/products -name "*.json" -type f 2>/dev/null | wc -l)
          if [ "$json_count" -eq 0 ]; then
            echo "‚ùå No JSON data files found in data/products/"
            echo "Checking for product files:"
            find data/ -name "*.json" -type f 2>/dev/null | head -10 || echo "No JSON files found"
            exit 1
          else
            echo "‚úÖ Found $json_count JSON data files"
            echo "Product types:"
            for type in templates components vectors plugins; do
              count=$(find data/products/$type -name "*.json" -type f 2>/dev/null | wc -l)
              if [ "$count" -gt 0 ]; then
                echo "  - $type: $count files"
              fi
            done
          fi
      
      - name: Check if sync already ran (prevent duplicate syncs)
        id: check-recent-sync
        if: github.event_name == 'schedule'
        run: |
          echo "üîç Checking if sync was already run recently by workflow_run trigger..."
          
          # Get current date in UTC (YYYY-MM-DD format)
          TODAY=$(date -u +%Y-%m-%d)
          echo "Today's date (UTC): $TODAY"
          
          # Check for successful sync runs triggered by workflow_run today
          # This prevents duplicate syncs when schedule runs at 8:00 UTC
          # but workflow_run already triggered sync earlier (e.g., at 2:30 UTC)
          RECENT_SYNC=$(gh run list --workflow=sync_to_db.yml --status=success --limit=10 --json databaseId,createdAt,event --jq ".[] | select(.event == \"workflow_run\") | select(.createdAt | startswith(\"$TODAY\")) | .databaseId" 2>/dev/null | head -1 || echo "")
          
          if [ -n "$RECENT_SYNC" ] && [ "$RECENT_SYNC" != "null" ]; then
            echo "‚úÖ Found sync run triggered by workflow_run today: $RECENT_SYNC"
            echo "‚è≠Ô∏è Skipping scheduled sync to prevent duplicate execution"
            echo "already_synced=true" >> $GITHUB_OUTPUT
          else
            echo "‚ÑπÔ∏è No sync found for today triggered by workflow_run - proceeding with scheduled sync"
            echo "already_synced=false" >> $GITHUB_OUTPUT
          fi
        env:
          GH_TOKEN: ${{ github.token }}
      
      - name: Sync JSON to Database
        if: github.event_name != 'schedule' || steps.check-recent-sync.outputs.already_synced != 'true'
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          if [ -z "$DATABASE_URL" ]; then
            echo "‚ö†Ô∏è DATABASE_URL not set in secrets. Skipping sync."
            exit 0
          fi
          python scripts/sync_json_to_db.py
      
      - name: Upload sync logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sync-logs
          path: logs/
          retention-days: 7

