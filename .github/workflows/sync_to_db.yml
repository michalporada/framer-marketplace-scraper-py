name: Sync JSON to Database

on:
  workflow_dispatch:  # Rƒôczne uruchomienie
  schedule:
    - cron: '0 3 * * *'  # Codziennie o 3:00 UTC (po scrapowaniu o 2:00)

jobs:
  sync:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Find latest scrape workflow run
        id: find-scrape-run
        continue-on-error: true
        run: |
          echo "üîç Looking for latest successful 'Daily Scrape' workflow run..."
          
          # Get latest successful run of scrape workflow
          RUN_ID=$(gh run list --workflow=scrape.yml --status=success --limit=1 --json databaseId --jq '.[0].databaseId' 2>/dev/null || echo "")
          
          if [ -z "$RUN_ID" ] || [ "$RUN_ID" == "null" ]; then
            echo "‚ö†Ô∏è No successful scrape workflow run found"
            echo "run_id=" >> $GITHUB_OUTPUT
            echo "found=false" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ Found scrape workflow run: $RUN_ID"
            echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
            echo "found=true" >> $GITHUB_OUTPUT
          fi
        env:
          GH_TOKEN: ${{ github.token }}
      
      - name: Download artifacts (if available)
        id: download-artifacts
        continue-on-error: true
        if: steps.find-scrape-run.outputs.found == 'true'
        uses: actions/download-artifact@v4
        with:
          name: scraped-data-latest
          path: data/
          github-token: ${{ github.token }}
          repository: ${{ github.repository }}
          run-id: ${{ steps.find-scrape-run.outputs.run_id }}
      
      - name: Check download result
        id: check-download
        run: |
          if [ "${{ steps.download-artifacts.outcome }}" == "success" ]; then
            echo "üîç Checking artifact structure..."
            echo "Contents of data/ directory:"
            ls -la data/ 2>/dev/null || echo "data/ not found"
            echo ""
            echo "Looking for products directory..."
            if [ -d "data/products" ]; then
              echo "‚úÖ Found data/products/"
              ls -la data/products/ | head -10
            elif [ -d "data/data/products" ]; then
              echo "‚úÖ Found data/data/products/ (nested structure)"
              # Move nested structure to expected location
              mv data/data/* data/ 2>/dev/null || true
              rm -rf data/data 2>/dev/null || true
            else
              echo "‚ö†Ô∏è Neither data/products nor data/data/products found"
              echo "Searching for JSON files..."
              find data/ -name "*.json" -type f 2>/dev/null | head -10 || echo "No JSON files found"
            fi
            
            # Check if products directory exists now
            if [ -d "data/products" ] && [ -n "$(ls -A data/products/*/*.json 2>/dev/null)" ]; then
              echo "‚úÖ Artifact downloaded and extracted successfully"
              echo "downloaded=true" >> $GITHUB_OUTPUT
            else
              echo "‚ö†Ô∏è Artifact downloaded but no product files found"
              echo "downloaded=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "downloaded=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Check if artifact was downloaded
        run: |
          if [ "${{ steps.check-download.outputs.downloaded }}" != "true" ]; then
            echo "‚ö†Ô∏è Artifact 'scraped-data-latest' not found or download failed"
            echo "This may happen if:"
            echo "  - Scrape workflow hasn't run yet"
            echo "  - Scrape workflow failed"
            echo "  - Artifact expired (retention: 7 days)"
            echo ""
            echo "Checking if data/ directory exists locally..."
            if [ -d "data/products" ] && [ -n "$(ls -A data/products/*/*.json 2>/dev/null)" ]; then
              echo "‚úÖ Found local data files - will use them instead"
            else
              echo "‚ùå No data found. Cannot proceed with sync."
              exit 1
            fi
          else
            echo "‚úÖ Artifact downloaded successfully"
          fi
      
      - name: Check if data exists
        run: |
          if [ ! -d "data/products" ]; then
            echo "‚ùå data/products directory not found"
            echo "Available directories:"
            ls -la data/ 2>/dev/null || echo "data/ directory not found"
            exit 1
          fi
          
          json_count=$(find data/products -name "*.json" -type f 2>/dev/null | wc -l)
          if [ "$json_count" -eq 0 ]; then
            echo "‚ùå No JSON data files found in data/products/"
            echo "Checking for product files:"
            find data/ -name "*.json" -type f 2>/dev/null | head -10 || echo "No JSON files found"
            exit 1
          else
            echo "‚úÖ Found $json_count JSON data files"
            echo "Product types:"
            for type in templates components vectors plugins; do
              count=$(find data/products/$type -name "*.json" -type f 2>/dev/null | wc -l)
              if [ "$count" -gt 0 ]; then
                echo "  - $type: $count files"
              fi
            done
          fi
      
      - name: Sync JSON to Database
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          if [ -z "$DATABASE_URL" ]; then
            echo "‚ö†Ô∏è DATABASE_URL not set in secrets. Skipping sync."
            exit 0
          fi
          python scripts/sync_json_to_db.py
      
      - name: Upload sync logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sync-logs
          path: logs/
          retention-days: 7

